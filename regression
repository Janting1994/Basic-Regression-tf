# -*- coding: utf-8 -*-
"""
Created on Wed Sep 27 09:51:17 2017

@author: janti
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

# 添加层
def add_layer(inputs, in_size, out_size, activation_function=None):
    # add one more layer and return the output of this layer
    # 区别：大框架，定义层 layer，里面有 小部件
    with tf.name_scope('layer'):
     # 区别：小部件
     with tf.name_scope('weights'):
         Weights = tf.Variable(tf.random_normal([in_size, out_size]),name='W')
     with tf.name_scope('biases'):
         biases = tf.Variable(tf.zeros([1, out_size]) + 0.1,name='b')
     with tf.name_scope('Wx_plus_b'):
         Wx_plus_b = tf.matmul(inputs, Weights) + biases
    if activation_function is None:
        outputs = Wx_plus_b
    else:
        outputs = activation_function(Wx_plus_b)
    return outputs

# 1.训练的数据
# Make up some real data 
x_data = np.linspace(-1,1,300)[:, np.newaxis]
noise = np.random.normal(0, 0.05, x_data.shape)
y_data = 2*np.square(x_data)+ 0.5 + noise  #*x_data + x_data

# 2.定义节点准备接收数据
# define placeholder for inputs to network  
# 区别：大框架，里面有 inputs x，y
with tf.name_scope('inputs'):
    xs = tf.placeholder(tf.float32, [None, 1],name='x_input')
    ys = tf.placeholder(tf.float32, [None, 1],name='y_input')
    y_prediction = tf.placeholder(tf.float32, [None, 1],name='y_prediction')
# add hidden layer 输入值是 xs，在隐藏层有 10 个神经元 
with tf.name_scope('layer1'):  
    l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)
# add output layer 输入值是隐藏层 l1，在预测层输出 1 个结果
  #  l2 = add_layer(l1, 10, 10, activation_function=None)
with tf.name_scope('layer2'): 
    prediction = add_layer(l1, 10, 1, activation_function=None)

# 4.定义 loss 表达式
# the error between prediciton and real data  

with tf.name_scope('function'):
    loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction),reduction_indices=[1]))

# 5.选择 optimizer 使 loss 达到最小                   
# 这一行定义了用什么方式去减少 loss，学习率是 0.1   
with tf.name_scope('train'):      
    train_Optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)

# important step 对所有变量进行初始化
init = tf.initialize_all_variables()
sess = tf.Session()
# 上面定义的都没有运算，直到 sess.run 才会开始运算
writer = tf.summary.FileWriter("C:/neural_1_logs", sess.graph)
#writer = tf.train.SummaryWriter('/root/tensor-board/logs/mnist_logs', sess.graph)
sess.run(init)

# 迭代 1000 次学习，sess.run optimizer
for i in range(1000):
    # training train_step 和 loss 都是由 placeholder 定义的运算，所以这里要用 feed 传入参数
    sess.run(train_Optimizer, feed_dict={xs: x_data, ys: y_data})
    
    if i % 50 == 0:
        # to see the step improvement
        print(sess.run(loss, feed_dict={xs: x_data, ys: y_data}))


# 1.测试的数据
# Make up some test data 

#x_data_test = np.linspace(-1,1,300)[:, np.newaxis]
y_prediction=sess.run(prediction, feed_dict={xs: x_data})       
plt.figure()  
plt.plot(x_data,y_data,'b',x_data,y_prediction,'r')  
plt.show() 
